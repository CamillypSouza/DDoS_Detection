{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e204d5-89a9-438d-8ba0-4d267c7bd4f2",
   "metadata": {},
   "source": [
    "ANÁLISE DO DATASET ORIGINAL CONCATENADO (DOIS DIAS DE CAPTURA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d70cc6-1afb-4eea-b269-96deb10570ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------\n",
    "# Carregar dataset concatenado\n",
    "# -----------------------------\n",
    "files = [\n",
    "    \"Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "]\n",
    "\n",
    "chunk_size = 500000\n",
    "dfs = []\n",
    "\n",
    "for file in files:\n",
    "    for chunk in pd.read_csv(file, chunksize=chunk_size, low_memory=False):\n",
    "        chunk.columns = [c.strip() for c in chunk.columns]\n",
    "        dfs.append(chunk)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Shape do dataset concatenado:\", df.shape)\n",
    "\n",
    "# Limpar coluna Label\n",
    "df['Label'] = df['Label'].astype(str).str.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Distribuição de Labels\n",
    "# -----------------------------\n",
    "label_counts = df['Label'].value_counts()\n",
    "print(\"\\nDistribuição de Labels:\")\n",
    "print(label_counts)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(data=df, x='Label', order=label_counts.index)\n",
    "plt.title(\"Distribuição de Labels\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Protocolos presentes\n",
    "# -----------------------------\n",
    "protocol_counts = df['Protocol'].value_counts()\n",
    "print(\"\\nProtocolos presentes e suas contagens:\")\n",
    "print(protocol_counts)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(data=df, x='Protocol', order=protocol_counts.index)\n",
    "plt.title(\"Distribuição de Protocolos\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Estatísticas descritivas\n",
    "# -----------------------------\n",
    "print(\"\\nEstatísticas descritivas das colunas numéricas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Correlação entre features numéricas\n",
    "# -----------------------------\n",
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "corr_matrix = df[num_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)\n",
    "plt.title(\"Matriz de Correlação entre Features Numéricas\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Outliers - Boxplots de algumas colunas importantes\n",
    "# -----------------------------\n",
    "cols_outlier_check = ['Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',\n",
    "                      'TotLen Fwd Pkts', 'TotLen Bwd Pkts']\n",
    "\n",
    "for col in cols_outlier_check:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    sns.boxplot(x='Label', y=col, data=df)\n",
    "    plt.title(f\"Boxplot de {col} por Label\")\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Distribuição de pacotes Forward e Backward\n",
    "# -----------------------------\n",
    "df['Fwd/Bwd Packet Ratio'] = df['Tot Fwd Pkts'] / (df['Tot Bwd Pkts'] + 1)  # +1 para evitar divisão por zero\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['Fwd/Bwd Packet Ratio'], bins=50, kde=True)\n",
    "plt.title(\"Distribuição da Razão Fwd/Bwd Packets\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Flags TCP (se existirem)\n",
    "# -----------------------------\n",
    "tcp_flags = ['FIN Flag Cnt','SYN Flag Cnt','PSH Flag Cnt','ACK Flag Cnt','URG Flag Cnt','CWE Flag Count','ECE Flag Cnt']\n",
    "for flag in tcp_flags:\n",
    "    if flag in df.columns:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        sns.boxplot(x='Label', y=flag, data=df)\n",
    "        plt.title(f\"{flag} por Label\")\n",
    "        plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Ports mais usadas\n",
    "# -----------------------------\n",
    "for col in ['Src Port', 'Dst Port']:\n",
    "    if col in df.columns:\n",
    "        top_ports = df[col].value_counts().head(20)\n",
    "        plt.figure(figsize=(12,5))\n",
    "        sns.barplot(x=top_ports.index, y=top_ports.values)\n",
    "        plt.title(f\"Top 20 {col}s\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Fluxos Forward/Backward Bytes\n",
    "# -----------------------------\n",
    "if 'TotLen Fwd Pkts' in df.columns and 'TotLen Bwd Pkts' in df.columns:\n",
    "    df['Fwd/Bwd Bytes Ratio'] = df['TotLen Fwd Pkts'] / (df['TotLen Bwd Pkts'] + 1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(df['Fwd/Bwd Bytes Ratio'], bins=50, kde=True)\n",
    "    plt.title(\"Distribuição da Razão Fwd/Bwd Bytes\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c55e0-b60e-41e3-8804-b641d76eac35",
   "metadata": {},
   "source": [
    "PRÉ PROCESSAMENTO, BALANCEAMENTO E SALVAMENTO DA SAMPLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f681aa-6741-42e7-890a-84b2532112b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "files = [\n",
    "    \"Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Colunas relevantes\n",
    "# -----------------------------\n",
    "cols_to_keep = [\n",
    "    'Label', 'Protocol', 'Src Port', 'Dst Port',\n",
    "    'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',\n",
    "    'TotLen Fwd Pkts', 'TotLen Bwd Pkts',\n",
    "    'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean',\n",
    "    'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
    "    'FIN Flag Cnt', 'SYN Flag Cnt', 'PSH Flag Cnt',\n",
    "    'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt'\n",
    "]\n",
    "\n",
    "chunk_size = 500000\n",
    "dfs = []\n",
    "\n",
    "# -----------------------------\n",
    "# Ler em chunks e acumular\n",
    "# -----------------------------\n",
    "for file in files:\n",
    "    for chunk in pd.read_csv(file, chunksize=chunk_size, low_memory=False):\n",
    "        # Limpar nomes de colunas (remove espaços extras)\n",
    "        chunk.columns = [c.strip() for c in chunk.columns]\n",
    "        \n",
    "        # Manter apenas colunas existentes\n",
    "        cols_existentes = [c for c in cols_to_keep if c in chunk.columns]\n",
    "        chunk = chunk[cols_existentes]\n",
    "        \n",
    "        # Limpar strings da coluna Label\n",
    "        chunk['Label'] = chunk['Label'].astype(str).str.strip()\n",
    "        \n",
    "        # Remover linhas com Label ausente\n",
    "        chunk = chunk[chunk['Label'] != 'nan']\n",
    "        dfs.append(chunk)\n",
    "\n",
    "# Concatenar todos os chunks\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "del dfs\n",
    "print(\"Shape após concatenação:\", df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Remover duplicatas\n",
    "# -----------------------------\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(\"Shape após remoção de duplicatas:\", df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Converter colunas numéricas\n",
    "# -----------------------------\n",
    "for col in df.columns:\n",
    "    if col != 'Label':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# -----------------------------\n",
    "# Transformar Label em binária (0 = benigno, 1 = ataque)\n",
    "# -----------------------------\n",
    "df['Label'] = np.where(df['Label'].str.lower() == 'benign', 0, 1)\n",
    "\n",
    "# -----------------------------\n",
    "# Remover linhas com Label ausente (safety)\n",
    "# -----------------------------\n",
    "df = df.dropna(subset=['Label'])\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# -----------------------------\n",
    "# Preencher NaN nas colunas numéricas com a mediana\n",
    "# -----------------------------\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# -----------------------------\n",
    "# Remover outliers (clipping 1% e 99%)\n",
    "# -----------------------------\n",
    "for col in num_cols:\n",
    "    q_low = df[col].quantile(0.01)\n",
    "    q_high = df[col].quantile(0.99)\n",
    "    df[col] = df[col].clip(q_low, q_high)\n",
    "\n",
    "print(\"Shape após clipping de outliers:\", df.shape)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Remover features altamente correlacionadas\n",
    "# -----------------------------\n",
    "# calcular a correlação apenas entre colunas numéricas (exceto Label)\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != 'Label']\n",
    "corr_matrix = df[num_cols].corr().abs()\n",
    "\n",
    "# Seleciona o triângulo superior da matriz de correlação\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# threshold para correlação alta \n",
    "threshold = 0.95\n",
    "\n",
    "# encontra colunas que têm correlação maior que threshold com outra coluna\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "if to_drop:\n",
    "    print(f\"Colunas com correlação > {threshold} que serão removidas ({len(to_drop)}):\")\n",
    "    print(to_drop)\n",
    "    df = df.drop(columns=to_drop)\n",
    "else:\n",
    "    print(\"Nenhuma coluna altamente correlacionada encontrada acima do threshold.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Atualiza lista de colunas numéricas após remoção\n",
    "# -----------------------------\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != 'Label']\n",
    "\n",
    "# -----------------------------\n",
    "# Checagem rápida de exemplos \n",
    "# -----------------------------\n",
    "counts = df['Label'].value_counts()\n",
    "print(\"Contagem após limpeza (0=benign,1=attack):\")\n",
    "print(counts)\n",
    "\n",
    "# -----------------------------\n",
    "# Criar amostra balanceada (600.000 linhas)\n",
    "# -----------------------------\n",
    "n_total = 600000\n",
    "n_benign = int(n_total * 0.9)   # 90% benigno\n",
    "n_ddos = n_total - n_benign     # 10% DDoS\n",
    "\n",
    "if counts.get(0, 0) < n_benign or counts.get(1, 0) < n_ddos:\n",
    "    raise ValueError(\n",
    "        f\"Não há exemplos suficientes: benignos={counts.get(0,0)}, ataques={counts.get(1,0)}. \"\n",
    "        \"Ajuste n_total ou revise os arquivos lidos.\"\n",
    "    )\n",
    "\n",
    "df_benign = df[df['Label'] == 0].sample(n=n_benign, random_state=42)\n",
    "df_ddos = df[df['Label'] == 1].sample(n=n_ddos, random_state=42)\n",
    "\n",
    "df_sample = pd.concat([df_benign, df_ddos], ignore_index=True)\n",
    "df_sample = df_sample.sample(frac=1, random_state=42)  # embaralhar\n",
    "\n",
    "print(\"Shape da amostra final:\", df_sample.shape)\n",
    "print(\"Distribuição da coluna Label (0 = benigno, 1 = ataque):\")\n",
    "print(df_sample['Label'].value_counts())\n",
    "\n",
    "# -----------------------------\n",
    "# Salvar a amostra final em CSV\n",
    "# -----------------------------\n",
    "df_sample.to_csv(\"df_sample.csv\", index=False)\n",
    "print(\"Arquivo df_sample.csv salvo com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289c099-54a8-4dfd-8ab2-e9f29f639b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificação das colunas do dataset original\n",
    "file = \"Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "df_head = pd.read_csv(file, nrows=5)  \n",
    "print(df_head.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
